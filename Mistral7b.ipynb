{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-14T00:44:44.315089Z","iopub.status.busy":"2024-04-14T00:44:44.314293Z","iopub.status.idle":"2024-04-14T00:45:04.801295Z","shell.execute_reply":"2024-04-14T00:45:04.800232Z","shell.execute_reply.started":"2024-04-14T00:44:44.315046Z"},"trusted":true},"outputs":[],"source":["!pip install -U datasets trl accelerate peft bitsandbytes packaging ninja sentencepiece transformers einops trl huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:45:04.803711Z","iopub.status.busy":"2024-04-14T00:45:04.803417Z","iopub.status.idle":"2024-04-14T00:45:17.102336Z","shell.execute_reply":"2024-04-14T00:45:17.101251Z","shell.execute_reply.started":"2024-04-14T00:45:04.803683Z"},"trusted":true},"outputs":[],"source":["!pip install tqdm scipy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:45:17.104411Z","iopub.status.busy":"2024-04-14T00:45:17.104009Z","iopub.status.idle":"2024-04-14T00:45:36.262646Z","shell.execute_reply":"2024-04-14T00:45:36.261880Z","shell.execute_reply.started":"2024-04-14T00:45:17.104376Z"},"trusted":true},"outputs":[],"source":["import os\n","from dataclasses import dataclass, field\n","from typing import Optional\n","\n","import torch\n","from datasets import load_dataset\n","from datasets import load_from_disk\n","from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n","\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    AutoTokenizer,\n","    TrainingArguments,\n",")\n","from tqdm.notebook import tqdm\n","\n","from trl import SFTTrainer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:45:36.264349Z","iopub.status.busy":"2024-04-14T00:45:36.263798Z","iopub.status.idle":"2024-04-14T00:48:32.959373Z","shell.execute_reply":"2024-04-14T00:48:32.958510Z","shell.execute_reply.started":"2024-04-14T00:45:36.264321Z"},"trusted":true},"outputs":[],"source":["from huggingface_hub import interpreter_login\n","interpreter_login()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:32.962041Z","iopub.status.busy":"2024-04-14T00:48:32.961762Z","iopub.status.idle":"2024-04-14T00:48:36.739486Z","shell.execute_reply":"2024-04-14T00:48:36.738112Z","shell.execute_reply.started":"2024-04-14T00:48:32.962015Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"nbertagnolli/counsel-chat\", split=\"train\")\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:36.741770Z","iopub.status.busy":"2024-04-14T00:48:36.741124Z","iopub.status.idle":"2024-04-14T00:48:37.156905Z","shell.execute_reply":"2024-04-14T00:48:37.155814Z","shell.execute_reply.started":"2024-04-14T00:48:36.741717Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","# Convert to DataFrame\n","df = pd.DataFrame(dataset)\n","\n","# Display the first few rows of the DataFrame\n","df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:37.158569Z","iopub.status.busy":"2024-04-14T00:48:37.158216Z","iopub.status.idle":"2024-04-14T00:48:37.501812Z","shell.execute_reply":"2024-04-14T00:48:37.500804Z","shell.execute_reply.started":"2024-04-14T00:48:37.158536Z"},"trusted":true},"outputs":[],"source":["\n","# Filter the required columns\n","#filtered_df = df[['questionText', 'topic']].drop_duplicates()\n","filtered_df = df[['questionText', 'topic', 'answerText']].drop_duplicates(subset=['questionText', 'topic'])\n","# Rename the columns\n","filtered_df.columns = ['Context', 'topic', 'Response']\n","\n","# Group by topic and count the occurrences\n","topic_counts = filtered_df['topic'].value_counts()\n","\n","# Calculate the target number of samples per topic for the test set\n","target_test_size_per_topic = (topic_counts * 0.2).round().astype(int)\n","\n","# Initialize an empty DataFrame for the test set\n","test_set_balanced = pd.DataFrame(columns=filtered_df.columns)\n","\n","# Initialize an empty DataFrame for the train set\n","train_set_balanced = pd.DataFrame(columns=filtered_df.columns)\n","\n","# For each topic, randomly select the calculated number of samples to include in the test set\n","for topic, target_size in target_test_size_per_topic.items():\n","    samples = filtered_df[filtered_df['topic'] == topic].sample(n=min(target_size, topic_counts[topic]), random_state=42)\n","    test_set_balanced = pd.concat([test_set_balanced, samples])\n","\n","        # Add the remaining samples to the train set\n","    train_set_balanced = pd.concat([train_set_balanced, df[df['topic'] == topic].drop(samples.index)])\n","\n","print(\"train data shape\",train_set_balanced.shape )\n","print(\"test data shape\",test_set_balanced.shape )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:37.505020Z","iopub.status.busy":"2024-04-14T00:48:37.504735Z","iopub.status.idle":"2024-04-14T00:48:37.712809Z","shell.execute_reply":"2024-04-14T00:48:37.711730Z","shell.execute_reply.started":"2024-04-14T00:48:37.504995Z"},"trusted":true},"outputs":[],"source":["\n","# Save the balanced test set\n","test_set_balanced.to_csv('counsel_chat_test_balanced.csv', index=False)\n","\n","# Save the balanced train set\n","train_set_balanced.to_csv('counsel_chat_train_balanced.csv', index=False)\n","\n","\n","# Check the final distribution of topics in the balanced test set\n","balanced_test_distribution = test_set_balanced['topic'].value_counts()\n","\n","print(balanced_test_distribution)\n","print(\"test data shape: \\n\",test_set_balanced.head() )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:37.714358Z","iopub.status.busy":"2024-04-14T00:48:37.714042Z","iopub.status.idle":"2024-04-14T00:48:37.774544Z","shell.execute_reply":"2024-04-14T00:48:37.773606Z","shell.execute_reply.started":"2024-04-14T00:48:37.714333Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(\"counsel_chat_train_balanced.csv\")\n","\n","# Filter the required columns\n","df = train_df[['questionText', 'answerText']]\n","# Rename the columns\n","df.columns = ['Context', 'Response']\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:37.776098Z","iopub.status.busy":"2024-04-14T00:48:37.775826Z","iopub.status.idle":"2024-04-14T00:48:37.831694Z","shell.execute_reply":"2024-04-14T00:48:37.830788Z","shell.execute_reply.started":"2024-04-14T00:48:37.776074Z"},"trusted":true},"outputs":[],"source":["\n","# Function to transform the row into desired format\n","def format_row(row):\n","    question = row['Context']\n","    answer = row['Response']\n","    formatted_string = f\"<s>[INST] {question} [/INST] {answer}</s>\"\n","    return formatted_string\n","\n","# Apply the function to each row of the dataframe\n","df['Formatted'] = df.apply(format_row, axis=1)\n","\n","# Rename the 'Formatted' column to 'Text'\n","new_df = df.rename(columns={'Formatted': 'Text'})\n","\n","new_df\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:37.833134Z","iopub.status.busy":"2024-04-14T00:48:37.832841Z","iopub.status.idle":"2024-04-14T00:48:37.856375Z","shell.execute_reply":"2024-04-14T00:48:37.855441Z","shell.execute_reply.started":"2024-04-14T00:48:37.833095Z"},"trusted":true},"outputs":[],"source":["## \n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","# Assuming 'final_df' is your DataFrame loaded with pd.read_csv(\"formatted_data.csv\")\n","#train_df, test_df = train_test_split(new_df, test_size=0.2, random_state=42)  # Splitting 20% for testing\n","\n","# Save the train and test datasets to CSV files\n","#test_df.to_csv('test_data.csv', index=False)\n","train_df = new_df.sample(frac=1, random_state=42)\n","\n","test_df = pd.read_csv(\"counsel_chat_test_balanced.csv\")\n","\n","print(test_df.shape)\n","print(train_df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:37.857903Z","iopub.status.busy":"2024-04-14T00:48:37.857568Z","iopub.status.idle":"2024-04-14T00:48:38.046562Z","shell.execute_reply":"2024-04-14T00:48:38.045515Z","shell.execute_reply.started":"2024-04-14T00:48:37.857876Z"},"trusted":true},"outputs":[],"source":["\n","# If you want to save the new dataframe to a CSV file:\n","train_df = train_df[['Text']]\n","train_df.to_csv('train_formatted_data.csv', index=False)\n","final_df = pd.read_csv(\"train_formatted_data.csv\")\n","final_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:38.048106Z","iopub.status.busy":"2024-04-14T00:48:38.047825Z","iopub.status.idle":"2024-04-14T00:48:38.539615Z","shell.execute_reply":"2024-04-14T00:48:38.538786Z","shell.execute_reply.started":"2024-04-14T00:48:38.048081Z"},"trusted":true},"outputs":[],"source":["\n","training_dataset = load_dataset(\"csv\", data_files=\"train_formatted_data.csv\", split=\"train\")\n","#print(dataset[\"Text\"][400])\n","training_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:38.544427Z","iopub.status.busy":"2024-04-14T00:48:38.544085Z","iopub.status.idle":"2024-04-14T00:48:38.859165Z","shell.execute_reply":"2024-04-14T00:48:38.858101Z","shell.execute_reply.started":"2024-04-14T00:48:38.544404Z"},"trusted":true},"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:48:38.860626Z","iopub.status.busy":"2024-04-14T00:48:38.860336Z","iopub.status.idle":"2024-04-14T00:51:46.151815Z","shell.execute_reply":"2024-04-14T00:51:46.150468Z","shell.execute_reply.started":"2024-04-14T00:48:38.860602Z"},"trusted":true},"outputs":[],"source":["base_model = \"/kaggle/input/mistral/pytorch/7b-v0.1-hf/1\"\n","\n","# Load base model(Mistral 7B)\n","bnb_config = BitsAndBytesConfig(  \n","    load_in_4bit= True,\n","    bnb_4bit_quant_type= \"nf4\",\n","    bnb_4bit_compute_dtype= torch.bfloat16,\n","    bnb_4bit_use_double_quant= False,\n",")\n","\n","\n","import gc\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","        base_model,\n","        quantization_config=bnb_config,\n","        torch_dtype=torch.bfloat16,\n","        device_map=\"auto\",\n","        trust_remote_code=True,\n",")\n","\n","model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n","model.config.pretraining_tp = 1\n","model.gradient_checkpointing_enable()\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n","tokenizer.padding_side = 'right'\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.add_eos_token = True\n","tokenizer.add_bos_token, tokenizer.add_eos_token\n","\n","\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","model = prepare_model_for_kbit_training(model)\n","peft_config = LoraConfig(\n","    lora_alpha=32,\n","    lora_dropout=0.1,\n","    r=8,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",")\n","\n","model = get_peft_model(model, peft_config)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:51:46.153535Z","iopub.status.busy":"2024-04-14T00:51:46.153209Z","iopub.status.idle":"2024-04-14T00:51:47.873231Z","shell.execute_reply":"2024-04-14T00:51:47.872409Z","shell.execute_reply.started":"2024-04-14T00:51:46.153505Z"},"trusted":true},"outputs":[],"source":["\n","#Hyperparamter\n","training_arguments = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=2,\n","    per_device_train_batch_size=1,\n","    gradient_accumulation_steps=1,\n","    optim=\"paged_adamw_32bit\",\n","    save_steps=1000,\n","    logging_steps=1000,\n","    learning_rate=2e-4,\n","    weight_decay=0.001,\n","    fp16=False,\n","    bf16=False,\n","    max_grad_norm=0.3,\n","    max_steps=-1,\n","    warmup_ratio=0.03,\n","    group_by_length=True,\n","    lr_scheduler_type=\"constant\",\n","    report_to=\"wandb\"\n",")\n","\n","\n","# Setting sft parameters\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=training_dataset,\n","    peft_config=peft_config,\n","    max_seq_length= None, # 690\n","    dataset_text_field=\"Text\",\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n","    packing= False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:51:47.874623Z","iopub.status.busy":"2024-04-14T00:51:47.874349Z","iopub.status.idle":"2024-04-14T00:51:48.197104Z","shell.execute_reply":"2024-04-14T00:51:48.196049Z","shell.execute_reply.started":"2024-04-14T00:51:47.874598Z"},"trusted":true},"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T00:51:48.199221Z","iopub.status.busy":"2024-04-14T00:51:48.198713Z","iopub.status.idle":"2024-04-14T05:04:46.401151Z","shell.execute_reply":"2024-04-14T05:04:46.400151Z","shell.execute_reply.started":"2024-04-14T00:51:48.199173Z"},"trusted":true},"outputs":[],"source":["trainer.train() "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:04:46.403133Z","iopub.status.busy":"2024-04-14T05:04:46.402707Z","iopub.status.idle":"2024-04-14T05:04:54.205616Z","shell.execute_reply":"2024-04-14T05:04:54.204597Z","shell.execute_reply.started":"2024-04-14T05:04:46.403090Z"},"trusted":true},"outputs":[],"source":["\n","import torch\n","\n","# Save the model weights\n","model.save_pretrained(\"Mistral7b-finetuned\")\n","\n","# For saving PyTorch model\n","torch.save(model.state_dict(), \"Mistral7b-finetuned.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T05:04:54.207514Z","iopub.status.busy":"2024-04-14T05:04:54.207163Z","iopub.status.idle":"2024-04-14T09:05:40.293025Z","shell.execute_reply":"2024-04-14T09:05:40.291902Z","shell.execute_reply.started":"2024-04-14T05:04:54.207479Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","from transformers import pipeline\n","\n","n = 0\n","# Placeholder for the generated responses\n","generated_responses = []\n","\n","model.config.use_cache = True\n","model.eval()\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n","tokenizer.padding_side = 'right'\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.add_eos_token = True\n","tokenizer.add_bos_token, tokenizer.add_eos_token\n","pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, \n","                max_length=1024)\n","\n","test_df = pd.read_csv(\"counsel_chat_test_balanced.csv\")\n","test_df['Context'] = test_df['Context'].fillna('')\n","\n","for index, row in tqdm(test_df.iterrows()):\n","    prompt = f\"[INST] {row['Context'][:940]} [/INST]\"\n","    reference = row['Response']\n","    \n","    result = pipe(prompt)\n","    generated_text = result[0]['generated_text']\n","    #print(generated_text)\n","    \n","    generated_responses.append({\n","            'Context': row['Context'],\n","            'topic': row['topic'],\n","            'Response': generated_text\n","        })\n","    \n","\n","    if n < 5:\n","        print(\"Context:\",row['Context'])\n","        print(\"generated_text:\",generated_text)\n","        print(\"reference:\",reference)\n","    \n","    n +=1\n","    \n","# Create a DataFrame from the generated responses\n","generated_df = pd.DataFrame(generated_responses)\n","\n","# Write the DataFrame to an Excel file\n","generated_df.to_excel('Mistral7B_preds.xlsx', index=False)\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"isSourceIdPinned":true,"modelInstanceId":3899,"sourceId":5111,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
